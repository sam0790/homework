{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "informed-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix, mean_squared_error as MSE\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "violent-herald",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22.08</td>\n",
       "      <td>11.460</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>22.67</td>\n",
       "      <td>7.000</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>29.58</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>21.67</td>\n",
       "      <td>11.500</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.17</td>\n",
       "      <td>8.170</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.960</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1</td>\n",
       "      <td>31.57</td>\n",
       "      <td>10.500</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>6.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1</td>\n",
       "      <td>20.67</td>\n",
       "      <td>0.415</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0</td>\n",
       "      <td>18.83</td>\n",
       "      <td>9.540</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0</td>\n",
       "      <td>27.42</td>\n",
       "      <td>14.500</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>3.085</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>1</td>\n",
       "      <td>41.00</td>\n",
       "      <td>0.040</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A1     A2      A3  A4  A5  A6     A7  A8  A9  A10  A11  A12  A13   A14  \\\n",
       "0     1  22.08  11.460   2   4   4  1.585   0   0    0    1    2  100  1213   \n",
       "1     0  22.67   7.000   2   8   4  0.165   0   0    0    0    2  160     1   \n",
       "2     0  29.58   1.750   1   4   4  1.250   0   0    0    1    2  280     1   \n",
       "3     0  21.67  11.500   1   5   3  0.000   1   1   11    1    2    0     1   \n",
       "4     1  20.17   8.170   2   6   4  1.960   1   1   14    0    2   60   159   \n",
       "..   ..    ...     ...  ..  ..  ..    ...  ..  ..  ...  ...  ...  ...   ...   \n",
       "685   1  31.57  10.500   2  14   4  6.500   1   0    0    0    2    0     1   \n",
       "686   1  20.67   0.415   2   8   4  0.125   0   0    0    0    2    0    45   \n",
       "687   0  18.83   9.540   2   6   4  0.085   1   0    0    0    2  100     1   \n",
       "688   0  27.42  14.500   2  14   8  3.085   1   1    1    0    2  120    12   \n",
       "689   1  41.00   0.040   2  10   4  0.040   0   1    1    0    1  560     1   \n",
       "\n",
       "     A15  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      1  \n",
       "4      1  \n",
       "..   ...  \n",
       "685    1  \n",
       "686    0  \n",
       "687    1  \n",
       "688    1  \n",
       "689    1  \n",
       "\n",
       "[690 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../australian.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-evening",
   "metadata": {},
   "source": [
    "### 1.\tPreprocess your dataset. Indicate which steps worked and which didn’t. Include your thoughts on why certain steps worked and certain steps didn’t. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "federal-albert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A1      690 non-null    int64  \n",
      " 1   A2      690 non-null    float64\n",
      " 2   A3      690 non-null    float64\n",
      " 3   A4      690 non-null    int64  \n",
      " 4   A5      690 non-null    int64  \n",
      " 5   A6      690 non-null    int64  \n",
      " 6   A7      690 non-null    float64\n",
      " 7   A8      690 non-null    int64  \n",
      " 8   A9      690 non-null    int64  \n",
      " 9   A10     690 non-null    int64  \n",
      " 10  A11     690 non-null    int64  \n",
      " 11  A12     690 non-null    int64  \n",
      " 12  A13     690 non-null    int64  \n",
      " 13  A14     690 non-null    int64  \n",
      " 14  A15     690 non-null    int64  \n",
      "dtypes: float64(3), int64(12)\n",
      "memory usage: 81.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ignored-cambodia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1     2.185398e-01\n",
       "A2     1.405001e+02\n",
       "A3     2.478211e+01\n",
       "A4     1.849540e-01\n",
       "A5     1.356644e+01\n",
       "A6     3.969323e+00\n",
       "A7     1.119915e+01\n",
       "A8     2.498244e-01\n",
       "A9     2.451042e-01\n",
       "A10    2.364819e+01\n",
       "A11    2.485938e-01\n",
       "A12    8.928925e-02\n",
       "A13    2.963882e+04\n",
       "A14    2.714517e+07\n",
       "A15    2.473255e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-connection",
   "metadata": {},
   "source": [
    "#### Selecting features for Model (Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "coordinate-asbestos",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'A11',\n",
      "       'A12', 'A13', 'A14'],\n",
      "      dtype='object')\n",
      "[False False False  True  True False  True  True  True  True  True  True\n",
      " False False]\n",
      "[3 5 4 1 1 2 1 1 1 1 1 1 6 7]\n"
     ]
    }
   ],
   "source": [
    "#feature selection\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "X = df.drop('A15',axis=1)\n",
    "y = df['A15']\n",
    "\n",
    "reg = LinearRegression()\n",
    "rfe = RFE(reg,n_features_to_select=8)\n",
    "rfe_ = rfe.fit(X, y)\n",
    "\n",
    "print(X.columns)\n",
    "print(rfe_.support_)\n",
    "print(rfe.ranking_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-zealand",
   "metadata": {},
   "source": [
    "#### Droping columns that are not important/redundant for model based on above RFE feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "soviet-emperor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1.960</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>6.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>3.085</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A4  A5     A7  A8  A9  A10  A11  A12  A15\n",
       "0     2   4  1.585   0   0    0    1    2    0\n",
       "1     2   8  0.165   0   0    0    0    2    0\n",
       "2     1   4  1.250   0   0    0    1    2    0\n",
       "3     1   5  0.000   1   1   11    1    2    1\n",
       "4     2   6  1.960   1   1   14    0    2    1\n",
       "..   ..  ..    ...  ..  ..  ...  ...  ...  ...\n",
       "685   2  14  6.500   1   0    0    0    2    1\n",
       "686   2   8  0.125   0   0    0    0    2    0\n",
       "687   2   6  0.085   1   0    0    0    2    1\n",
       "688   2  14  3.085   1   1    1    0    2    1\n",
       "689   2  10  0.040   0   1    1    0    1    1\n",
       "\n",
       "[690 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.drop(['A1','A2','A3','A6','A13','A14'],axis=1)\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-isolation",
   "metadata": {},
   "source": [
    "#### Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adult-manchester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2.boxplot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "painful-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing outliers with nulls in all the feature columns\n",
    "\n",
    "for x in ['A4','A5','A7','A8','A9','A10','A11','A12']:\n",
    "    q75,q25 = np.percentile(df2.loc[:,x],[75,25])\n",
    "    intr_qr = q75-q25\n",
    "\n",
    "    max = q75+(1.5*intr_qr)\n",
    "    min = q25-(1.5*intr_qr)\n",
    "\n",
    "    df2.loc[df2[x] < min,x] = np.nan\n",
    "    df2.loc[df2[x] > max,x] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tired-proposal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A4     165\n",
       "A5       0\n",
       "A7      63\n",
       "A8       0\n",
       "A9       0\n",
       "A10     79\n",
       "A11      0\n",
       "A12     65\n",
       "A15      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "raising-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping all null values from Dataframe\n",
    "df2 = df2.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sunset-assault",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A4     0\n",
       "A5     0\n",
       "A7     0\n",
       "A8     0\n",
       "A9     0\n",
       "A10    0\n",
       "A11    0\n",
       "A12    0\n",
       "A15    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "executed-overview",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.040</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>374 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A4    A5     A7   A8   A9  A10  A11  A12  A15\n",
       "0    2.0   4.0  1.585  0.0  0.0  0.0  1.0  2.0    0\n",
       "1    2.0   8.0  0.165  0.0  0.0  0.0  0.0  2.0    0\n",
       "5    2.0   8.0  1.500  1.0  1.0  2.0  0.0  2.0    1\n",
       "6    2.0   3.0  0.125  0.0  0.0  0.0  0.0  2.0    0\n",
       "7    2.0  11.0  3.040  1.0  1.0  6.0  0.0  2.0    1\n",
       "..   ...   ...    ...  ...  ...  ...  ...  ...  ...\n",
       "682  2.0  13.0  0.040  1.0  0.0  0.0  0.0  2.0    1\n",
       "683  2.0   3.0  0.335  0.0  0.0  0.0  0.0  2.0    0\n",
       "686  2.0   8.0  0.125  0.0  0.0  0.0  0.0  2.0    0\n",
       "687  2.0   6.0  0.085  1.0  0.0  0.0  0.0  2.0    1\n",
       "688  2.0  14.0  3.085  1.0  1.0  1.0  0.0  2.0    1\n",
       "\n",
       "[374 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe after removing null values\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-salad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "creative-georgia",
   "metadata": {},
   "source": [
    "### 2.\tCreate a decision tree model tuned to the best of your abilities. Explain how you tuned it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "reported-surgeon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 1 1\n",
      " 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df2.drop('A15',axis=1)\n",
    "y = df2['A15']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "\n",
    "model = tree.DecisionTreeClassifier(max_depth= 4, random_state=42)\n",
    "\n",
    "\n",
    "model = model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "informed-assignment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38  5]\n",
      " [ 5 27]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "conventional-paint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88        43\n",
      "           1       0.84      0.84      0.84        32\n",
      "\n",
      "    accuracy                           0.87        75\n",
      "   macro avg       0.86      0.86      0.86        75\n",
      "weighted avg       0.87      0.87      0.87        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "identified-challenge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \",metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-tribune",
   "metadata": {},
   "source": [
    "### With Decision tree model we got accuracy score of 0.86666. Now we will try runing our model to improve accuracy score using GridSeachCV method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "quiet-folks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "# Checking all the parameters \n",
    "print(model.get_params())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "coral-employment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=DecisionTreeClassifier(max_depth=4, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': [3, 4, 5, 6],\n",
       "                         'max_features': [0.2, 0.3, 0.5, 0.8],\n",
       "                         'min_samples_leaf': [0.04, 0.06, 0.08]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating gridSeachCV with some parameters combination\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params_dt = {'max_depth': [3,4,5,6],\n",
    "            'min_samples_leaf':[0.04,0.06,0.08],\n",
    "            'max_features':[0.2,0.3,0.5,0.8]}\n",
    "\n",
    "grid_dt = GridSearchCV(estimator=model,param_grid=params_dt, scoring='accuracy', cv=10, n_jobs=-1)\n",
    "\n",
    "grid_dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "curious-determination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters :/n {'max_depth': 4, 'max_features': 0.8, 'min_samples_leaf': 0.06}\n"
     ]
    }
   ],
   "source": [
    "best_hyp = grid_dt.best_params_\n",
    "\n",
    "print('Best hyperparameters :/n' , best_hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "smooth-novelty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV accuracy 0.8862068965517242\n"
     ]
    }
   ],
   "source": [
    "best_cv_score = grid_dt.best_score_\n",
    "\n",
    "\n",
    "print('Best CV accuracy',best_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "desirable-minister",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=4, max_features=0.8, min_samples_leaf=0.06,\n",
      "                       random_state=42)\n"
     ]
    }
   ],
   "source": [
    "#best_model = tree.DecisionTreeClassifier(max_depth= 5, random_state=42, max_features= 0.8, min_samples_leaf=0.04)\n",
    "best_model = grid_dt.best_estimator_\n",
    "print(grid_dt.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "wicked-moderator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 1 1\n",
      " 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "best_model = best_model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "lined-draft",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37  6]\n",
      " [ 3 29]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "treated-access",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.88\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score after tuning model with best estimators \n",
    "\n",
    "print(\"Accuracy: \",metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-magnitude",
   "metadata": {},
   "source": [
    "### Using GridSeachCV method for tuning up our model we got slight increase in accuracy score. It got up from 0.86666 to 0.88. In tunning up model we used different combination of hyperparameters. We used max_depth, min_samples_leaf and max_features and provided some values so it can run model on these combinations. We used [3,4,5,6] for max_depth for the decision tree, [0.04,0.06,0.08] for min_samples_leaf and [0.2,0.3,0.5,0.8] for max_features and ran model on this hyperparameters to find best combination. Usng best_estimator_ we found out that max_depth=4, max_features=0.8 and min_samples_leaf=0.06 were best hyperparamters and gave us 0.88 accuracy score. I tried changing some values for those hyperparameters but I was not able to get more than 0.88. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-observer",
   "metadata": {},
   "source": [
    "### 3.\tCreate a random forest model tuned to the best of your abilities. Explain how you tuned it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "meaning-improvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "wireless-personality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 1 1\n",
      " 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "rf_model = rf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "corporate-projector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37  6]\n",
      " [ 3 29]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "together-reader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        43\n",
      "           1       0.83      0.91      0.87        32\n",
      "\n",
      "    accuracy                           0.88        75\n",
      "   macro avg       0.88      0.88      0.88        75\n",
      "weighted avg       0.88      0.88      0.88        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "adult-lafayette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.88\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \",metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-marine",
   "metadata": {},
   "source": [
    "#### Now we will try to tune our model to see if we get any better score. But we decreased score instead. Without tuning up we got .88 and after tuning up the model score went down to 0.85. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "southern-singer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 4,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 42,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "according-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rf = {'n_estimators':[100,200,300,400,500],\n",
    "            'max_depth':[4,5,6,7],\n",
    "            'min_samples_leaf':[0.01,0.02,0.03,0.04],\n",
    "             'max_features':['log2','sqrt']\n",
    "            }\n",
    "\n",
    "grid_rf = GridSearchCV(estimator = rf, param_grid = params_rf, cv=10, scoring='accuracy',n_jobs=-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "consistent-expert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=RandomForestClassifier(max_depth=4, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': [4, 5, 6, 7],\n",
       "                         'max_features': ['log2', 'sqrt'],\n",
       "                         'min_samples_leaf': [0.01, 0.02, 0.03, 0.04],\n",
       "                         'n_estimators': [100, 200, 300, 400, 500]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "received-sculpture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters :/n {'max_depth': 4, 'max_features': 0.8, 'min_samples_leaf': 0.06}\n"
     ]
    }
   ],
   "source": [
    "best_hyp = grid_dt.best_params_\n",
    "\n",
    "print('Best hyperparameters :/n' , best_hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "plain-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestrf_model = grid_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "suspended-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_rf = bestrf_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "cosmetic-thesaurus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 1 0 1 1 1 1 0 1 0 0 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 1 1\n",
      " 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = bestrf_model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "divine-ozone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36  7]\n",
      " [ 4 28]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "internal-hardwood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8533333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \",metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-information",
   "metadata": {},
   "source": [
    "### 4.\tCreate an xgboost model tuned to the best of your abilities. Explain how you tuned it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "periodic-devices",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:46:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python38\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "X = df2.drop('A15',axis=1)\n",
    "y = df2['A15']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bound-headset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 1 1\n",
      " 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "changing-registration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.88\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print('Accuracy score :',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-vacation",
   "metadata": {},
   "source": [
    "#### Now we will try to tune up our xgboost model using GridSeachCV method so it will have better accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "polish-anger",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = {'n_estimators':[100,200,300,400,500],\n",
    "            'max_depth':[4,5,6,7],\n",
    "            'tree_method': ['auto','exact','hist']\n",
    "            }\n",
    "\n",
    "grid_xgb = GridSearchCV(estimator = xgb, param_grid = params_xgb, cv=10, scoring='accuracy',n_jobs=-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "banner-server",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python38\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:48:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                                     importance_type='gain',\n",
       "                                     interaction_constraints='',\n",
       "                                     learning_rate=0.300000012,\n",
       "                                     max_delta_step=0, max_depth=6,\n",
       "                                     min_child_weight=1, missing=nan,\n",
       "                                     monotone_constraints='()',\n",
       "                                     n_estimators=100, n_jobs=4,\n",
       "                                     num_parallel_tree=1, random_state=42,\n",
       "                                     reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, subsample=1,\n",
       "                                     tree_method='exact', validate_parameters=1,\n",
       "                                     verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': [4, 5, 6, 7],\n",
       "                         'n_estimators': [100, 200, 300, 400, 500],\n",
       "                         'tree_method': ['auto', 'exact', 'hist']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "optical-charles",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters :/n {'max_depth': 7, 'n_estimators': 200, 'tree_method': 'hist'}\n"
     ]
    }
   ],
   "source": [
    "best_hyp = grid_xgb.best_params_\n",
    "\n",
    "print('Best hyperparameters :/n' , best_hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "theoretical-concentrate",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestxgb_model = grid_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cutting-rates",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:50:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "best_model_xgb = bestxgb_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "historic-retreat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 1 1\n",
      " 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = bestxgb_model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "impressed-boring",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37  6]\n",
      " [ 4 28]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "sunrise-hello",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \",metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-nicholas",
   "metadata": {},
   "source": [
    "#### With tuning up our model for xgboost I saw decrease in accuracy score. I tried different hyper parameters but was not able to get better score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-usage",
   "metadata": {},
   "source": [
    "### 5.\tWhich model performed best? What is your performance metric? Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-geometry",
   "metadata": {},
   "source": [
    "#### Decision Tree model with GridSearchCV method and Random forest (without tune up) and XGBoost (without tune up) got the best score of 0.88. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-economy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
