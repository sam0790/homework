{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "solid-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix, mean_squared_error as MSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-cartridge",
   "metadata": {},
   "source": [
    "### 1.\tWhat is a neural network? What are the general steps required to build a neural network? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-beads",
   "metadata": {},
   "source": [
    "#### Neural network is a network that reflect behaviour of human brain to solve problem. In other words, it mimic behavior of human brain allowing computer programs to recognize patterns and solve the problem in the field of machine learning, AI and deep learning. Neural network contains nodes which are also called neurons (just like human neuron cell). Neural networks are comprised of a node layers, containing an input layer, one or more hidden layers, and an output layer. Each node connects to another and has associated weights and threshold. \n",
    "\n",
    "#### Neural Networks consist of three main parts: the input layer, the hidden layer, and the output layer. If we have multiple hidden layer then our network is also called deep learning network. Multiple hidden layers are necessary when we are trying to make any complex predictions. In order to build neural network we first need dataset. Once we have dataset then we can decide architecture of our neural network. Some of the aspects of neural network architecture is as below.\n",
    "\n",
    "#### Number of input nodes: The way to identify number of input nodes is identify the number of features.\n",
    "#### Number of hidden layers: The default is to use the single or one hidden layer. But we can use multiple hidden layers for complex dataset. \n",
    "#### Number of nodes in each of the hidden layers: In case of using multiple hidden layers, the best practice is to use same number of nodes in each hidden layer. In general practice, the number of hidden units is taken as comparable number to that of number of input nodes. That means one could take either the same number of hidden nodes as input nodes or maybe twice or thrice the number of input nodes.\n",
    "#### Number of output nodes: The way to identify number of output nodes is to identify the number of output classes you want the neural network to process.\n",
    "\n",
    "#### Once we have architecture in place then we need to implement forward propogation, activation function and backward propogation. In forward propagation, we apply a set of weights to the input data and calculate an output. For the first forward propagation, the set of weights is selected randomly. In back propagation, we measure the margin of error of the output and adjust the weights accordingly to decrease the error. It is the method of fine-tuning the weights of a neural network based on the error rate obtained in the previous epoch (i.e., iteration). Proper tuning of the weights allows you to reduce error rates and make the model reliable by increasing its generalization. Activation functions define one by one at layers. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-monthly",
   "metadata": {},
   "source": [
    "### 2.\tGenerally, how do you check the performance of a neural network? Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-tablet",
   "metadata": {},
   "source": [
    "For a classifier Neural Network, the metrics tend to be ‘Accuracy’, ‘Loss’ and so on. \n",
    "\n",
    "For a Regression Neural Network, the metrics are ‘Correlation Factor’, ‘Loss’, ‘Binary_Cross_Entropy’ and so on.\n",
    "\n",
    "With using these performance check we can check how far the predictions of our neural network is from actual result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-polish",
   "metadata": {},
   "source": [
    "### 3.\tCreate a neural network using keras to predict the outcome of either of these datasets: \n",
    "\n",
    "Cardiac Arrhythmia: https://archive.ics.uci.edu/ml/datasets/Arrhythmia \n",
    "\n",
    "Abalone age: https://archive.ics.uci.edu/ml/datasets/Abalone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "horizontal-acquisition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>F</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>M</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>M</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>F</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>M</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       "0      M   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1      M   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2      F   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3      M   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4      I   0.330     0.255   0.080        0.2050          0.0895   \n",
       "...   ..     ...       ...     ...           ...             ...   \n",
       "4172   F   0.565     0.450   0.165        0.8870          0.3700   \n",
       "4173   M   0.590     0.440   0.135        0.9660          0.4390   \n",
       "4174   M   0.600     0.475   0.205        1.1760          0.5255   \n",
       "4175   F   0.625     0.485   0.150        1.0945          0.5310   \n",
       "4176   M   0.710     0.555   0.195        1.9485          0.9455   \n",
       "\n",
       "      Viscera_weight  Shell_weight  Rings  \n",
       "0             0.1010        0.1500     15  \n",
       "1             0.0485        0.0700      7  \n",
       "2             0.1415        0.2100      9  \n",
       "3             0.1140        0.1550     10  \n",
       "4             0.0395        0.0550      7  \n",
       "...              ...           ...    ...  \n",
       "4172          0.2390        0.2490     11  \n",
       "4173          0.2145        0.2605     10  \n",
       "4174          0.2875        0.3080      9  \n",
       "4175          0.2610        0.2960     10  \n",
       "4176          0.3765        0.4950     12  \n",
       "\n",
       "[4177 rows x 9 columns]"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../abalone_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "chinese-adelaide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4177 entries, 0 to 4176\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Sex             4177 non-null   object \n",
      " 1   Length          4177 non-null   float64\n",
      " 2   Diameter        4177 non-null   float64\n",
      " 3   Height          4177 non-null   float64\n",
      " 4   Whole_weight    4177 non-null   float64\n",
      " 5   Shucked_weight  4177 non-null   float64\n",
      " 6   Viscera_weight  4177 non-null   float64\n",
      " 7   Shell_weight    4177 non-null   float64\n",
      " 8   Rings           4177 non-null   int64  \n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 293.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "exposed-season",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       "0    2   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1    2   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2    0   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3    2   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4    1   0.330     0.255   0.080        0.2050          0.0895   \n",
       "\n",
       "   Viscera_weight  Shell_weight  Rings  \n",
       "0          0.1010         0.150     15  \n",
       "1          0.0485         0.070      7  \n",
       "2          0.1415         0.210      9  \n",
       "3          0.1140         0.155     10  \n",
       "4          0.0395         0.055      7  "
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nominal values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "class_labels = LabelEncoder()\n",
    "\n",
    "df['Sex']=class_labels.fit_transform(df['Sex'].values)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "ethical-wealth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       1\n",
       "2       1\n",
       "3      15\n",
       "4      57\n",
       "5     115\n",
       "6     259\n",
       "7     391\n",
       "8     568\n",
       "9     689\n",
       "10    634\n",
       "11    487\n",
       "12    267\n",
       "13    203\n",
       "14    126\n",
       "15    103\n",
       "16     67\n",
       "17     58\n",
       "18     42\n",
       "19     32\n",
       "20     26\n",
       "21     14\n",
       "22      6\n",
       "23      9\n",
       "24      2\n",
       "25      1\n",
       "26      1\n",
       "27      2\n",
       "29      1\n",
       "Name: Rings, dtype: int64"
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rings'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-marsh",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "flying-internet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>0</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>2</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>2</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4124 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       "0       2   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1       2   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2       0   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3       2   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4       1   0.330     0.255   0.080        0.2050          0.0895   \n",
       "...   ...     ...       ...     ...           ...             ...   \n",
       "4172    0   0.565     0.450   0.165        0.8870          0.3700   \n",
       "4173    2   0.590     0.440   0.135        0.9660          0.4390   \n",
       "4174    2   0.600     0.475   0.205        1.1760          0.5255   \n",
       "4175    0   0.625     0.485   0.150        1.0945          0.5310   \n",
       "4176    2   0.710     0.555   0.195        1.9485          0.9455   \n",
       "\n",
       "      Viscera_weight  Shell_weight  Rings  \n",
       "0             0.1010        0.1500     15  \n",
       "1             0.0485        0.0700      7  \n",
       "2             0.1415        0.2100      9  \n",
       "3             0.1140        0.1550     10  \n",
       "4             0.0395        0.0550      7  \n",
       "...              ...           ...    ...  \n",
       "4172          0.2390        0.2490     11  \n",
       "4173          0.2145        0.2605     10  \n",
       "4174          0.2875        0.3080      9  \n",
       "4175          0.2610        0.2960     10  \n",
       "4176          0.3765        0.4950     12  \n",
       "\n",
       "[4124 rows x 9 columns]"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df[(df['Rings'] < 21) & (df['Rings']>3)]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "moved-berkeley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4      57\n",
       "5     115\n",
       "6     259\n",
       "7     391\n",
       "8     568\n",
       "9     689\n",
       "10    634\n",
       "11    487\n",
       "12    267\n",
       "13    203\n",
       "14    126\n",
       "15    103\n",
       "16     67\n",
       "17     58\n",
       "18     42\n",
       "19     32\n",
       "20     26\n",
       "Name: Rings, dtype: int64"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Rings'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "organized-recommendation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sex', 'Length', 'Diameter', 'Height', 'Whole_weight', 'Shucked_weight',\n",
      "       'Viscera_weight', 'Shell_weight'],\n",
      "      dtype='object')\n",
      "[False False  True  True  True  True  True  True]\n",
      "[3 2 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#feature selection\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "X = df2.drop('Rings',axis=1)\n",
    "y = df2['Rings']\n",
    "\n",
    "reg = LinearRegression()\n",
    "rfe = RFE(reg,n_features_to_select=6)\n",
    "rfe_ = rfe.fit(X, y)\n",
    "\n",
    "print(X.columns)\n",
    "print(rfe_.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "alternative-baltimore",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>0</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>2</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>2</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4124 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       "0       2   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1       2   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2       0   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3       2   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4       1   0.330     0.255   0.080        0.2050          0.0895   \n",
       "...   ...     ...       ...     ...           ...             ...   \n",
       "4172    0   0.565     0.450   0.165        0.8870          0.3700   \n",
       "4173    2   0.590     0.440   0.135        0.9660          0.4390   \n",
       "4174    2   0.600     0.475   0.205        1.1760          0.5255   \n",
       "4175    0   0.625     0.485   0.150        1.0945          0.5310   \n",
       "4176    2   0.710     0.555   0.195        1.9485          0.9455   \n",
       "\n",
       "      Viscera_weight  Shell_weight  Rings  \n",
       "0             0.1010        0.1500     15  \n",
       "1             0.0485        0.0700      7  \n",
       "2             0.1415        0.2100      9  \n",
       "3             0.1140        0.1550     10  \n",
       "4             0.0395        0.0550      7  \n",
       "...              ...           ...    ...  \n",
       "4172          0.2390        0.2490     11  \n",
       "4173          0.2145        0.2605     10  \n",
       "4174          0.2875        0.3080      9  \n",
       "4175          0.2610        0.2960     10  \n",
       "4176          0.3765        0.4950     12  \n",
       "\n",
       "[4124 rows x 9 columns]"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df2 = df2.drop(['Sex'],axis=1)\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "personal-offense",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2.boxplot(figsize=(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "generic-brain",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "# Replacing outliers with nulls in all the feature columns\n",
    "\n",
    "for x in ['Length','Diameter', 'Height', 'Whole_weight', 'Shucked_weight', 'Viscera_weight','Shell_weight']:\n",
    "    q75,q25 = np.percentile(df2.loc[:,x],[75,25])\n",
    "    intr_qr = q75-q25\n",
    "\n",
    "    max = q75+(1.5*intr_qr)\n",
    "    min = q25-(1.5*intr_qr)\n",
    "\n",
    "    df2.loc[df2[x] < min,x] = np.nan\n",
    "    df2.loc[df2[x] > max,x] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "known-designer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex                0\n",
       "Length            36\n",
       "Diameter          44\n",
       "Height            21\n",
       "Whole_weight      29\n",
       "Shucked_weight    48\n",
       "Viscera_weight    27\n",
       "Shell_weight      40\n",
       "Rings              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "western-accused",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping all null values from Dataframe\n",
    "df2 = df2.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "transsexual-architecture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>0</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>2</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>2</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3986 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       "0       2   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1       2   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2       0   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3       2   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4       1   0.330     0.255   0.080        0.2050          0.0895   \n",
       "...   ...     ...       ...     ...           ...             ...   \n",
       "4172    0   0.565     0.450   0.165        0.8870          0.3700   \n",
       "4173    2   0.590     0.440   0.135        0.9660          0.4390   \n",
       "4174    2   0.600     0.475   0.205        1.1760          0.5255   \n",
       "4175    0   0.625     0.485   0.150        1.0945          0.5310   \n",
       "4176    2   0.710     0.555   0.195        1.9485          0.9455   \n",
       "\n",
       "      Viscera_weight  Shell_weight  Rings  \n",
       "0             0.1010        0.1500     15  \n",
       "1             0.0485        0.0700      7  \n",
       "2             0.1415        0.2100      9  \n",
       "3             0.1140        0.1550     10  \n",
       "4             0.0395        0.0550      7  \n",
       "...              ...           ...    ...  \n",
       "4172          0.2390        0.2490     11  \n",
       "4173          0.2145        0.2605     10  \n",
       "4174          0.2875        0.3080      9  \n",
       "4175          0.2610        0.2960     10  \n",
       "4176          0.3765        0.4950     12  \n",
       "\n",
       "[3986 rows x 9 columns]"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe after removing null values\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "ignored-laugh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex               0.675524\n",
       "Length            0.012215\n",
       "Diameter          0.008412\n",
       "Height            0.001262\n",
       "Whole_weight      0.198941\n",
       "Shucked_weight    0.040655\n",
       "Viscera_weight    0.010246\n",
       "Shell_weight      0.015715\n",
       "Rings             8.504708\n",
       "dtype: float64"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "fixed-maker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3986 entries, 0 to 4176\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Sex             3986 non-null   int32  \n",
      " 1   Length          3986 non-null   float64\n",
      " 2   Diameter        3986 non-null   float64\n",
      " 3   Height          3986 non-null   float64\n",
      " 4   Whole_weight    3986 non-null   float64\n",
      " 5   Shucked_weight  3986 non-null   float64\n",
      " 6   Viscera_weight  3986 non-null   float64\n",
      " 7   Shell_weight    3986 non-null   float64\n",
      " 8   Rings           3986 non-null   int64  \n",
      "dtypes: float64(7), int32(1), int64(1)\n",
      "memory usage: 295.8 KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "multiple-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.astype({'Sex': np.float,'Rings':np.float})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "female-realtor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3986 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       "0     2.0   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1     2.0   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2     0.0   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3     2.0   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4     1.0   0.330     0.255   0.080        0.2050          0.0895   \n",
       "...   ...     ...       ...     ...           ...             ...   \n",
       "4172  0.0   0.565     0.450   0.165        0.8870          0.3700   \n",
       "4173  2.0   0.590     0.440   0.135        0.9660          0.4390   \n",
       "4174  2.0   0.600     0.475   0.205        1.1760          0.5255   \n",
       "4175  0.0   0.625     0.485   0.150        1.0945          0.5310   \n",
       "4176  2.0   0.710     0.555   0.195        1.9485          0.9455   \n",
       "\n",
       "      Viscera_weight  Shell_weight  Rings  \n",
       "0             0.1010        0.1500   15.0  \n",
       "1             0.0485        0.0700    7.0  \n",
       "2             0.1415        0.2100    9.0  \n",
       "3             0.1140        0.1550   10.0  \n",
       "4             0.0395        0.0550    7.0  \n",
       "...              ...           ...    ...  \n",
       "4172          0.2390        0.2490   11.0  \n",
       "4173          0.2145        0.2605   10.0  \n",
       "4174          0.2875        0.3080    9.0  \n",
       "4175          0.2610        0.2960   10.0  \n",
       "4176          0.3765        0.4950   12.0  \n",
       "\n",
       "[3986 rows x 9 columns]"
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "polyphonic-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardised the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df3 = pd.DataFrame(scaler.fit_transform(df2),columns=df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "unlike-literacy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.468376</td>\n",
       "      <td>-1.235495</td>\n",
       "      <td>-0.659898</td>\n",
       "      <td>-0.627562</td>\n",
       "      <td>-0.748918</td>\n",
       "      <td>-0.659129</td>\n",
       "      <td>1.765316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.558061</td>\n",
       "      <td>-1.376163</td>\n",
       "      <td>-1.306675</td>\n",
       "      <td>-1.247476</td>\n",
       "      <td>-1.267568</td>\n",
       "      <td>-1.297234</td>\n",
       "      <td>-0.976949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.130951</td>\n",
       "      <td>-0.110157</td>\n",
       "      <td>-0.294474</td>\n",
       "      <td>-0.468864</td>\n",
       "      <td>-0.348816</td>\n",
       "      <td>-0.180550</td>\n",
       "      <td>-0.291383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.468376</td>\n",
       "      <td>-0.391491</td>\n",
       "      <td>-0.655414</td>\n",
       "      <td>-0.672196</td>\n",
       "      <td>-0.620490</td>\n",
       "      <td>-0.619247</td>\n",
       "      <td>0.051400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.667030</td>\n",
       "      <td>-1.657497</td>\n",
       "      <td>-1.352633</td>\n",
       "      <td>-1.297069</td>\n",
       "      <td>-1.356479</td>\n",
       "      <td>-1.416878</td>\n",
       "      <td>-0.976949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>0.457856</td>\n",
       "      <td>0.733848</td>\n",
       "      <td>0.176316</td>\n",
       "      <td>0.094018</td>\n",
       "      <td>0.614391</td>\n",
       "      <td>0.130526</td>\n",
       "      <td>0.394184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>0.348888</td>\n",
       "      <td>-0.110157</td>\n",
       "      <td>0.353423</td>\n",
       "      <td>0.436211</td>\n",
       "      <td>0.372354</td>\n",
       "      <td>0.222254</td>\n",
       "      <td>0.051400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3985</th>\n",
       "      <td>0.730278</td>\n",
       "      <td>1.859186</td>\n",
       "      <td>0.824214</td>\n",
       "      <td>0.865191</td>\n",
       "      <td>1.093525</td>\n",
       "      <td>0.601129</td>\n",
       "      <td>-0.291383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3986</th>\n",
       "      <td>0.839246</td>\n",
       "      <td>0.311846</td>\n",
       "      <td>0.641503</td>\n",
       "      <td>0.892467</td>\n",
       "      <td>0.831730</td>\n",
       "      <td>0.505413</td>\n",
       "      <td>0.051400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3987</th>\n",
       "      <td>1.602026</td>\n",
       "      <td>1.577852</td>\n",
       "      <td>2.556052</td>\n",
       "      <td>2.948102</td>\n",
       "      <td>1.972760</td>\n",
       "      <td>2.092699</td>\n",
       "      <td>0.736967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3988 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Diameter    Height  Whole_weight  Shucked_weight  Viscera_weight  \\\n",
       "0    -0.468376 -1.235495     -0.659898       -0.627562       -0.748918   \n",
       "1    -1.558061 -1.376163     -1.306675       -1.247476       -1.267568   \n",
       "2     0.130951 -0.110157     -0.294474       -0.468864       -0.348816   \n",
       "3    -0.468376 -0.391491     -0.655414       -0.672196       -0.620490   \n",
       "4    -1.667030 -1.657497     -1.352633       -1.297069       -1.356479   \n",
       "...        ...       ...           ...             ...             ...   \n",
       "3983  0.457856  0.733848      0.176316        0.094018        0.614391   \n",
       "3984  0.348888 -0.110157      0.353423        0.436211        0.372354   \n",
       "3985  0.730278  1.859186      0.824214        0.865191        1.093525   \n",
       "3986  0.839246  0.311846      0.641503        0.892467        0.831730   \n",
       "3987  1.602026  1.577852      2.556052        2.948102        1.972760   \n",
       "\n",
       "      Shell_weight     Rings  \n",
       "0        -0.659129  1.765316  \n",
       "1        -1.297234 -0.976949  \n",
       "2        -0.180550 -0.291383  \n",
       "3        -0.619247  0.051400  \n",
       "4        -1.416878 -0.976949  \n",
       "...            ...       ...  \n",
       "3983      0.130526  0.394184  \n",
       "3984      0.222254  0.051400  \n",
       "3985      0.601129 -0.291383  \n",
       "3986      0.505413  0.051400  \n",
       "3987      2.092699  0.736967  \n",
       "\n",
       "[3988 rows x 7 columns]"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "wound-contamination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.005299     30\n",
       "-1.662516    101\n",
       "-1.319733    255\n",
       "-0.976949    391\n",
       "-0.634166    566\n",
       "-0.291383    685\n",
       " 0.051400    623\n",
       " 0.394184    468\n",
       " 0.736967    246\n",
       " 1.079750    195\n",
       " 1.422533    118\n",
       " 1.765316    102\n",
       " 2.108100     61\n",
       " 2.450883     52\n",
       " 2.793666     39\n",
       " 3.136449     32\n",
       " 3.479232     24\n",
       "Name: Rings, dtype: int64"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['Rings'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "anonymous-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "id": "entitled-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.drop('Rings',axis=1)\n",
    "y = df2['Rings']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,stratify=y,test_size = 0.2,random_state=42)\n",
    "\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "id": "least-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = X.shape[1]\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Set up the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(300, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Adding layers\n",
    "model.add(Dense(300, activation='relu'))\n",
    "\n",
    "model.add(Dense(300, activation='relu'))\n",
    "\n",
    "model.add(Dense(300, activation='relu'))\n",
    "\n",
    "model.add(Dense(300, activation='relu'))\n",
    "\n",
    "model.add(Dense(300,activation='relu'))\n",
    "\n",
    "model.add(Dense(300,activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "id": "adjusted-channel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 1s 9ms/step - loss: 36.7400 - val_loss: 5.9263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22107bdd670>"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',loss='mean_squared_error')\n",
    " \n",
    "# Fit the model\n",
    "model.fit(X_train,y_train,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "id": "mathematical-ballot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 5.3323\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 5.2303\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 4.3736\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 4.2077\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 4.3068\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 4.0287\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 7/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 4.4483\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 8/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 4.0651A: 0s - loss: 4.0\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 9/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 4.1883\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 10/40\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 3.8112\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 11/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 4.0858\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 12/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 4.1115\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 13/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 3.7411\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 14/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 3.8167\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 15/40\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 3.8471\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 16/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 3.7776\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 17/40\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 3.8235\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 18/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 3.6667\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 19/40\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 3.7021\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 20/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 3.6805\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 21/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 3.7779\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 22/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 3.6948\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 23/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 3.6956\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 24/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 3.6480\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 25/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 3.6108\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 26/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 3.6306\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 27/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 3.5512\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 28/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 3.6147\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 29/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 3.3964\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 30/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 3.5471\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 31/40\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 3.4970\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 32/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 3.4010\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 33/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 3.3094\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 34/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 3.3606\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 35/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 3.4167\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 36/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 3.2979\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 37/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 3.3346\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 38/40\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 3.2496\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 39/40\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 3.2808\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "Epoch 40/40\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 3.2192\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=40,callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "id": "returning-castle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7942129193604643\n"
     ]
    }
   ],
   "source": [
    "rmse = (3.2192)**(1/2)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-religious",
   "metadata": {},
   "source": [
    "### 4.\tWrite another algorithm to predict the same result as the previous question using either KNN or logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "id": "retained-louisiana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value for k=  1 is: 2.798137583257316\n",
      "RMSE value for k=  2 is: 2.3751401488790176\n",
      "RMSE value for k=  3 is: 2.273520278855709\n",
      "RMSE value for k=  4 is: 2.152892645222849\n",
      "RMSE value for k=  5 is: 2.1193936807339115\n",
      "RMSE value for k=  6 is: 2.120762356162798\n",
      "RMSE value for k=  7 is: 2.1114296421507275\n",
      "RMSE value for k=  8 is: 2.104049569932189\n",
      "RMSE value for k=  9 is: 2.117181177970104\n",
      "RMSE value for k=  10 is: 2.1271959021244466\n",
      "RMSE value for k=  11 is: 2.117907460643123\n",
      "RMSE value for k=  12 is: 2.1136433390845735\n",
      "RMSE value for k=  13 is: 2.117179426823269\n",
      "RMSE value for k=  14 is: 2.106375818446858\n",
      "RMSE value for k=  15 is: 2.1030060303496505\n",
      "RMSE value for k=  16 is: 2.0940135855106714\n",
      "RMSE value for k=  17 is: 2.0861271603441582\n",
      "RMSE value for k=  18 is: 2.085270147690381\n",
      "RMSE value for k=  19 is: 2.0856484682164704\n",
      "RMSE value for k=  20 is: 2.0870430630121573\n",
      "RMSE value for k=  21 is: 2.0868242622348543\n",
      "RMSE value for k=  22 is: 2.0864055931818597\n",
      "RMSE value for k=  23 is: 2.0915870680145927\n",
      "RMSE value for k=  24 is: 2.0943578396521434\n",
      "RMSE value for k=  25 is: 2.097444201987535\n",
      "RMSE value for k=  26 is: 2.1040929330549463\n",
      "RMSE value for k=  27 is: 2.106128935054722\n",
      "RMSE value for k=  28 is: 2.1103085839692843\n",
      "RMSE value for k=  29 is: 2.1105248253664337\n",
      "RMSE value for k=  30 is: 2.106955303661915\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "\n",
    "rmse_val = [] #to store rmse values for different k\n",
    "\n",
    "for K in range(30):\n",
    "    \n",
    "    K = K+1\n",
    "    model = neighbors.KNeighborsRegressor(n_neighbors = K)\n",
    "\n",
    "    model.fit(X_train, y_train)  #fit the model\n",
    "    y_pred = model.predict(X_test) #make prediction on test set\n",
    "    error = (mean_squared_error(y_test,y_pred)**(1/2)) #calculate rmse\n",
    "    rmse_val.append(error) #store rmse values\n",
    "    print('RMSE value for k= ' , K , 'is:', error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "id": "front-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From above for loop we can see k = 18 is best for this model\n",
    "KNN_model = neighbors.KNeighborsRegressor(n_neighbors = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "id": "liked-ordering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=18)"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df2.drop('Rings',axis=1)\n",
    "y = df2['Rings']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3, stratify=y, random_state=42)\n",
    "\n",
    "KNN_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "id": "technological-freight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.5        10.94444444 10.77777778 ...  6.22222222  6.77777778\n",
      "  8.77777778]\n"
     ]
    }
   ],
   "source": [
    "y_pred = KNN_model.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "error = mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "id": "impossible-surgery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE is: 2.089140302872671\n"
     ]
    }
   ],
   "source": [
    "print (\"The RMSE is:\",format(error**(1/2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-badge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "lyric-antarctica",
   "metadata": {},
   "source": [
    "### 5.\tCreate a neural network using pytorch to predict the same result as question 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "id": "psychological-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "X = df2.drop('Rings',axis=1).values\n",
    "y = df2['Rings'].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,stratify=y,test_size = 0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "temporal-telescope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.4300, 0.3200,  ..., 0.1635, 0.0800, 0.0900],\n",
      "        [2.0000, 0.3100, 0.2250,  ..., 0.0540, 0.0240, 0.0500],\n",
      "        [2.0000, 0.6000, 0.4750,  ..., 0.5490, 0.2875, 0.3600],\n",
      "        ...,\n",
      "        [1.0000, 0.3350, 0.2600,  ..., 0.0970, 0.0300, 0.0540],\n",
      "        [1.0000, 0.5350, 0.4200,  ..., 0.3980, 0.1965, 0.2500],\n",
      "        [0.0000, 0.5850, 0.4200,  ..., 0.4420, 0.2155, 0.2875]])\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "y_test = torch.FloatTensor(y_test)\n",
    "\n",
    "#print(X_train.shape)\n",
    "#print(X_test.shape)\n",
    "#print(y_train.shape)\n",
    "#print(y_test.shape)\n",
    "\n",
    "#y_train = y_train.view(-1,1)\n",
    "#y_test = y_test.view(-1,1)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "finished-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN_Model(nn.Module):\n",
    "    def __init__(self, input_features=8, hidden1=300, hidden2=300, hidden3=300,hidden4=300, hidden5=300, hidden6=300,\n",
    "                 hidden7=300, out_feature =1):\n",
    "        super().__init__()\n",
    "        self.layer_1_connection = nn.Linear(input_features, hidden1)\n",
    "        self.layer_2_connection = nn.Linear(hidden1, hidden2)\n",
    "        self.layer_3_connection = nn.Linear(hidden2, hidden3)\n",
    "        self.layer_4_connection = nn.Linear(hidden3, hidden4)\n",
    "        self.layer_5_connection = nn.Linear(hidden4, hidden5)\n",
    "        self.layer_6_connection = nn.Linear(hidden5, hidden6)\n",
    "        self.layer_7_connection = nn.Linear(hidden6, hidden7)\n",
    "        self.out = nn.Linear(hidden7, out_feature)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #apply activation functions\n",
    "        x = F.relu(self.layer_1_connection(x))\n",
    "        x = F.relu(self.layer_2_connection(x))\n",
    "        x = F.relu(self.layer_3_connection(x))\n",
    "        x = F.relu(self.layer_4_connection(x))\n",
    "        x = F.relu(self.layer_5_connection(x))\n",
    "        x = F.relu(self.layer_6_connection(x))\n",
    "        x = F.relu(self.layer_7_connection(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "id": "demanding-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "#instantiate the model\n",
    "model = ANN_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "id": "innocent-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "\n",
    "#optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "id": "instant-vision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 1 with loss: 8.607023239135742\n",
      "Epoch number: 11 with loss: 8.518616676330566\n",
      "Epoch number: 21 with loss: 8.507890701293945\n",
      "Epoch number: 31 with loss: 8.505471229553223\n",
      "Epoch number: 41 with loss: 8.505746841430664\n",
      "Epoch number: 51 with loss: 8.505614280700684\n",
      "Epoch number: 61 with loss: 8.505510330200195\n",
      "Epoch number: 71 with loss: 8.505477905273438\n",
      "Epoch number: 81 with loss: 8.505468368530273\n",
      "Epoch number: 91 with loss: 8.505465507507324\n",
      "Epoch number: 101 with loss: 8.505463600158691\n",
      "Epoch number: 111 with loss: 8.505461692810059\n",
      "Epoch number: 121 with loss: 8.505461692810059\n",
      "Epoch number: 131 with loss: 8.505461692810059\n",
      "Epoch number: 141 with loss: 8.505461692810059\n",
      "Epoch number: 151 with loss: 8.505461692810059\n",
      "Epoch number: 161 with loss: 8.505461692810059\n",
      "Epoch number: 171 with loss: 8.505461692810059\n",
      "Epoch number: 181 with loss: 8.505461692810059\n",
      "Epoch number: 191 with loss: 8.505461692810059\n",
      "Epoch number: 201 with loss: 8.505461692810059\n",
      "Epoch number: 211 with loss: 8.505461692810059\n",
      "Epoch number: 221 with loss: 8.505461692810059\n",
      "Epoch number: 231 with loss: 8.505461692810059\n",
      "Epoch number: 241 with loss: 8.505461692810059\n",
      "Epoch number: 251 with loss: 8.505461692810059\n",
      "Epoch number: 261 with loss: 8.505461692810059\n",
      "Epoch number: 271 with loss: 8.505461692810059\n",
      "Epoch number: 281 with loss: 8.505461692810059\n",
      "Epoch number: 291 with loss: 8.505461692810059\n",
      "Epoch number: 301 with loss: 8.505461692810059\n",
      "Epoch number: 311 with loss: 8.505461692810059\n",
      "Epoch number: 321 with loss: 8.505461692810059\n",
      "Epoch number: 331 with loss: 8.505461692810059\n",
      "Epoch number: 341 with loss: 8.505461692810059\n",
      "Epoch number: 351 with loss: 8.505461692810059\n",
      "Epoch number: 361 with loss: 8.505461692810059\n",
      "Epoch number: 371 with loss: 8.505461692810059\n",
      "Epoch number: 381 with loss: 8.505461692810059\n",
      "Epoch number: 391 with loss: 8.505461692810059\n",
      "Epoch number: 401 with loss: 8.505461692810059\n",
      "Epoch number: 411 with loss: 8.505461692810059\n",
      "Epoch number: 421 with loss: 8.505461692810059\n",
      "Epoch number: 431 with loss: 8.505461692810059\n",
      "Epoch number: 441 with loss: 8.505461692810059\n",
      "Epoch number: 451 with loss: 8.505461692810059\n",
      "Epoch number: 461 with loss: 8.505461692810059\n",
      "Epoch number: 471 with loss: 8.505461692810059\n",
      "Epoch number: 481 with loss: 8.505461692810059\n",
      "Epoch number: 491 with loss: 8.505461692810059\n"
     ]
    }
   ],
   "source": [
    "#run model through multiple epochs/iterations\n",
    "final_loss = []\n",
    "n_epochs = 500\n",
    "for epoch in range(n_epochs):\n",
    "    y_pred = model.forward(X_train)\n",
    "    loss = loss_function(y_pred, y_train)\n",
    "    final_loss.append(loss)\n",
    "    \n",
    "    if epoch % 10 == 1:\n",
    "        print(f'Epoch number: {epoch} with loss: {loss.item()}')\n",
    "    \n",
    "    optimizer.zero_grad() #zero the gradient before running backwards propagation\n",
    "    loss.backward() #for backward propagation \n",
    "    optimizer.step() #performs one optimization step each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "id": "preceding-permit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.916412469595146\n"
     ]
    }
   ],
   "source": [
    "rmse = (8.505461692810059)**(1/2)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-margin",
   "metadata": {},
   "source": [
    "### 6.\tCompare the performance of the neural networks to the other model you created. Which performed better? Why do you think that is?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-villa",
   "metadata": {},
   "source": [
    "#### The performance of the keras model returns RMSE of 1.79. When we use KNN method on same dataset we got RMSE of 2.08 whereas using pytorch we got RMSE of 2.91.  \n",
    "\n",
    "#### Keras model performed the best because it does have the lowest RMSE among the method we used. This is because we have tried different combination of hidden layers and also different number of nodes for each layers. We also tried different optimizer but we got best result with adam. KNN method got decent result but it was not any better than keras. In KNN we got the best KNN number but we can not define addition layers like in keras and this make this model less complex than keras model and thus we got better score on keras than KNN.\n",
    "\n",
    "#### I was surprised with pytorch model because I was expecting the best result out of all models we used. But surprisingly, we got worse score on this model. I have tried to change hidden layers and nodes per layer and also tried changing optimizer (tried adam and sgd) but result was not getting any better than we got here. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
